# Video Keyframe Retrieval System

Há»‡ thá»‘ng tÃ¬m kiáº¿m keyframe video Ä‘a phÆ°Æ¡ng thá»©c sá»­ dá»¥ng CLIP vÃ  Sentence Transformers, há»— trá»£ tÃ¬m kiáº¿m báº±ng hÃ¬nh áº£nh, vÄƒn báº£n CLIP, transcription vÃ  description.

---

## ğŸš€ TÃ­nh nÄƒng

### 4 PhÆ°Æ¡ng thá»©c TÃ¬m kiáº¿m
1. **CLIP Text Search** - TÃ¬m keyframe báº±ng mÃ´ táº£ vÄƒn báº£n (sá»­ dá»¥ng CLIP model)
2. **CLIP Image Search** - TÃ¬m keyframe tÆ°Æ¡ng tá»± báº±ng upload áº£nh (sá»­ dá»¥ng CLIP model)
3. **Transcription Search** - TÃ¬m keyframe qua ná»™i dung transcription (sá»­ dá»¥ng Sentence Transformer)
4. **Description Search** - TÃ¬m keyframe qua mÃ´ táº£ video (sá»­ dá»¥ng Sentence Transformer)

### CÃ´ng nghá»‡
- **Dual Model Architecture**: CLIP (RN50) + Sentence Transformers
- **FastAPI Backend**: RESTful API vá»›i CORS support
- **Modern Frontend**: Giao diá»‡n web responsive vá»›i animations
- **Pre-computed Embeddings**: TÃ¬m kiáº¿m nhanh vá»›i embeddings Ä‘Ã£ tÃ­nh sáºµn
- **Temporal Mapping**: Mapping keyframe vá»›i thÃ´ng tin temporal (frame_idx, pts_time)

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
rag_langchain_/
â”œâ”€â”€ backend/                        # FastAPI backend
â”‚   â”œâ”€â”€ main.py                    # API endpoints vÃ  khá»Ÿi táº¡o models
â”‚   â”œâ”€â”€ config.py                  # Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n vÃ  data models
â”‚   â”œâ”€â”€ models.py                  # Load CLIP vÃ  Sentence Transformer models
â”‚   â”œâ”€â”€ dataset.py                 # Dataset class quáº£n lÃ½ data
â”‚   â”œâ”€â”€ retrieval.py               # Logic tÃ¬m kiáº¿m (ClipRetrieval, TextRetrieval)
â”‚   â”œâ”€â”€ utils.py                   # Helper functions (load embeddings, mapping)
â”‚   â””â”€â”€ test.ipynb                 # Notebook Ä‘á»ƒ test
â”‚
â”œâ”€â”€ data/                          # Dá»¯ liá»‡u vÃ  embeddings
â”‚   â”œâ”€â”€ embs/                      # Pre-computed embeddings
â”‚   â”‚   â”œâ”€â”€ clip/                  # CLIP embeddings (.npy files)
â”‚   â”‚   â”œâ”€â”€ transcription/         # Transcription embeddings
â”‚   â”‚   â””â”€â”€ description/           # Description embeddings
â”‚   â”œâ”€â”€ info/                      # Metadata
â”‚   â”‚   â”œâ”€â”€ media/                 # Video info (title, watch_url)
â”‚   â”‚   â”œâ”€â”€ transcription/         # Transcription text
â”‚   â”‚   â””â”€â”€ description/           # Description text
â”‚   â”œâ”€â”€ keyframes/                 # Keyframe images (organized by video)
â”‚   â””â”€â”€ map-keyframes/             # Temporal mapping (frame_idx, pts_time, fps)
â”‚
â”œâ”€â”€ frontend/                      # Web UI
â”‚   â”œâ”€â”€ index.html                # Main HTML
â”‚   â”œâ”€â”€ style.css                 # Styling
â”‚   â”œâ”€â”€ app.js                    # JavaScript logic
â”‚   â””â”€â”€ README.md                 # Frontend docs
â”‚
â”œâ”€â”€ .env                          # Environment variables (HF_TOKEN, model IDs)
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

---

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone <repo-url>
cd rag_langchain_
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

**Dependencies chÃ­nh:**
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `torch` + `torchvision` - Deep learning
- `clip` - OpenAI CLIP model
- `sentence-transformers` - Text embeddings
- `pillow` - Image processing
- `python-dotenv` - Environment variables

### 3. Cáº¥u hÃ¬nh environment variables

Táº¡o file `.env` trong thÆ° má»¥c root:
```env
HF_TOKEN=your_huggingface_token
TEXT_MODEL_ID=your_text_embedding_model_id
CLIP_MODEL_ID=your_clip_model_id
```

### 4. Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº£m báº£o cáº¥u trÃºc thÆ° má»¥c `data/` Ä‘áº§y Ä‘á»§:
- Keyframes trong `data/keyframes/`
- Embeddings trong `data/embs/`
- Metadata trong `data/info/`
- Temporal mapping trong `data/map-keyframes/`

---

## ğŸ¯ Sá»­ dá»¥ng

### 1. Cháº¡y API Server

```bash
cd backend
uvicorn main:app --host 0.0.0.0 --port 8000
```

API sáº½ cháº¡y táº¡i: `http://localhost:8000`

### 2. Má»Ÿ Web Demo

Má»Ÿ `frontend/index.html` trong trÃ¬nh duyá»‡t hoáº·c dÃ¹ng Live Server.

---

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET /health
```
**Response:**
```json
{
  "status": "ok",
  "model": "your_clip_model_id",
  "num_images": 12345
}
```

### 1. CLIP Text Search
```bash
POST /search/clip_text
Content-Type: multipart/form-data

query: "a person playing guitar"
top_k: 100
```

### 2. CLIP Image Search
```bash
POST /search/clip_image
Content-Type: multipart/form-data

file: <image_file>
top_k: 100
```

### 3. Transcription Search
```bash
POST /search/transcription
Content-Type: multipart/form-data

query: "machine learning tutorial"
top_k: 100
```

### 4. Description Search
```bash
POST /search/description
Content-Type: multipart/form-data

query: "cooking recipe video"
top_k: 100
```

### Response Format
Táº¥t cáº£ endpoints tráº£ vá» danh sÃ¡ch `SearchResult`:
```json
[
  {
    "video_name": "L21_V001",
    "title": "60 GiÃ¢y SÃ¡ng - NgÃ y 01082024 - HTV Tin Tá»©c Má»›i Nháº¥t 2024",
    "watch_url": "https://youtube.com/embed/Rzpw5WR7nAY",
    "keyframes": [
      {
        "path": "keyframes/L21_V001/170.jpg",
        "frame_idx": 20702,
        "pts_time": 690.067,
        "similarity": 0.5121440857687809
      },
      {
        "path": "keyframes/L22_V023/232.jpg",
        "frame_idx": 23490,
        "pts_time": 939.6,
        "similarity": 0.4272028442152153
      }
    ]
  }
]
```

### Static Files
```bash
GET /static/keyframes/{video_folder}/{frame_number}.jpg
```

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

### Models

#### 1. CLIP Model (`models.py`)
```python
load_clip_model(device) -> (model, preprocess)
```
- Model: your_clip_model_id
- Sá»­ dá»¥ng cho: CLIP text/image search
- Output: 1024-dim embeddings (depends on model)

#### 2. Text Embedding Model (`models.py`)
```python
load_text_embedding_model(device) -> model
```
- Model: your_text_embedding_model_id
- Sá»­ dá»¥ng cho: Transcription/Description search
- Output: 384-dim embeddings (depends on model)

### Dataset (`dataset.py`)

Class `Dataset` quáº£n lÃ½ toÃ n bá»™ data:
```python
dataset = Dataset()
dataset.clip_embs              # CLIP embeddings
dataset.transcription_embs     # Transcription embeddings
dataset.description_embs       # Description embeddings
dataset.media_info            # Video metadata
dataset.transcription_info    # Transcription text + temporal mapping
dataset.description_info      # Description text + temporal mapping
dataset.keyframes             # Keyframe paths
dataset.map_keyframes         # Temporal info (frame_idx, pts_time, fps)
```

### Retrieval Classes (`retrieval.py`)

#### 1. ClipRetrieval
```python
clip_retriever = ClipRetrieval(model, preprocess, device)
clip_retriever.search_text(query, dataset, top_k)
clip_retriever.search_image(image, dataset, top_k)
results = clip_retriever.collect_results(dataset)
```

#### 2. TextRetrieval
```python
text_retriever = TextRetrieval(model, support_model, device)
text_retriever.search_text(query, dataset, "transcription", top_k)
results = text_retriever.collect_results(dataset, "transcription", top_k)
```

**Äáº·c biá»‡t:** TextRetrieval sá»­ dá»¥ng CLIP model nhÆ° support model Ä‘á»ƒ chá»n keyframe tá»‘t nháº¥t tá»« cÃ¡c keyframe cÃ³ cÃ¹ng transcription/description.

---

## ğŸ¨ Frontend Features

- **4 Search Tabs**: CLIP Text, CLIP Image, Transcription, Description
- **Drag & Drop**: Upload áº£nh dá»… dÃ ng
- **Real-time Preview**: Xem trÆ°á»›c áº£nh upload
- **Video Results**: Hiá»ƒn thá»‹ káº¿t quáº£ theo video vá»›i YouTube embed
- **Keyframe Gallery**: Xem táº¥t cáº£ keyframe tÃ¬m Ä‘Æ°á»£c vá»›i similarity scores
- **Responsive Design**: TÆ°Æ¡ng thÃ­ch mobile/desktop
- **Modern UI**: Animations, glassmorphism, gradient backgrounds

---

## ğŸ“Š Performance

- **CLIP Model**: your_clip_model_id 
- **Text Model**: your_text_embedding_model_id 
- **Search Speed**: ~10-100ms per query (depends on dataset size)
- **Embedding Dimensions**: 
  - CLIP: 1024
  - Text: 384 (default)
- **Similarity Metric**: Cosine similarity

---

## ğŸ”§ Customization

### Thay Ä‘á»•i CLIP model
Trong `.env`:
```env
CLIP_MODEL_ID=your_clip_model_id
```

### Thay Ä‘á»•i Text Embedding model
Trong `.env`:
```env
TEXT_MODEL_ID=your_text_embedding_model_id
```

### Äiá»u chá»‰nh temporal expansion
Trong `dataset.py`:
```python
# Má»Ÿ rá»™ng temporal window cho description search
self.description_info = mapping_temporal_keyframe(
    self.description_info, 
    self.map_keyframes, 
    expand_temporal=4  # Â±4 keyframes
)
```

---

## ğŸ› Troubleshooting

### CORS Error
Äáº£m báº£o API server Ä‘ang cháº¡y vÃ  CORS middleware Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh trong `main.py`.

### Model Download Failed
- Kiá»ƒm tra káº¿t ná»‘i internet
- Äáº£m báº£o `HF_TOKEN` há»£p lá»‡ trong `.env`
- CLIP model sáº½ tá»± Ä‘á»™ng download láº§n Ä‘áº§u (~350MB)

### Keyframe Not Found
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong `config.py`
- Äáº£m báº£o structure `data/keyframes/{video_name}/{frame}.jpg`

### Out of Memory
- Giáº£m batch size khi tÃ­nh embeddings
- Sá»­ dá»¥ng CPU thay vÃ¬ GPU: `device = "cpu"`
- Giáº£m `top_k` trong search

---

## ğŸ“š References

- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [OpenAI CLIP GitHub](https://github.com/openai/CLIP)
- [Sentence Transformers](https://www.sbert.net/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

---

## ğŸ“ Notes

- Embeddings Ä‘Æ°á»£c pre-compute Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ search
- CLIP há»— trá»£ zero-shot learning, khÃ´ng cáº§n training
- Temporal mapping giÃºp tÃ¬m Ä‘Ãºng thá»i Ä‘iá»ƒm trong video
- Support model (CLIP) trong TextRetrieval giÃºp chá»n keyframe tá»‘t nháº¥t khi cÃ³ nhiá»u keyframe match cÃ¹ng text
