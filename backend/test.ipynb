{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cbd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from dataset import Dataset\n",
    "from config import KEYFRAMES\n",
    "from utils import norm_vectors, get_video_name\n",
    "import pandas as pd\n",
    "from retrieval import ClipRetrieval\n",
    "import dataclasses\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2288bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ADMIN\\\\Downloads\\\\rag_langchain_\\\\data.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "p = r\"C:\\Users\\ADMIN\\Downloads\\rag_langchain_\\data\".replace(\"\\\\\", \"/\")\n",
    "shutil.make_archive(p, \"zip\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2633226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading clip embeddings: 100%|███████████████████████████████████| 128/128 [00:00<00:00, 278.43it/s]\n",
      "Loading image paths: 100%|███████████████████████████████████████| 128/128 [00:00<00:00, 857.63it/s]\n",
      "Loading media info: 100%|███████████████████████████████████████| 128/128 [00:00<00:00, 2713.33it/s]\n",
      "Loading map keyframes: 100%|█████████████████████████████████████| 128/128 [00:00<00:00, 594.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15472b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Loading CLIP model...\n",
      "INFO:root: CLIP model loaded.\n"
     ]
    }
   ],
   "source": [
    "retrive = ClipRetrieval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5170ee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.2593512535095215\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "retrive.search_text(\"a cat\")\n",
    "results = retrive.collect_results()\n",
    "print(\"Time: \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83617dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://youtube.com/embed/p6h043fMCUA\n"
     ]
    }
   ],
   "source": [
    "print(results[0].watch_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dataset.get_items(retrive.search_result[\"indexes\"])\n",
    "tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0532c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].pts_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(results[0].keyframe[4]).convert(\"RGB\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = {get_video_name(keyframe): [] for keyframe in collect_results[\"keyframes\"]}\n",
    "for keyframe in collect_results[\"keyframes\"]:\n",
    "    video_name = get_video_name(keyframe)\n",
    "    if video_name in collector.keys():\n",
    "        collector[video_name].append(keyframe)\n",
    "collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce287dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21188e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_results[\"keyframes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"C:\\Users\\ADMIN\\Downloads\\rag_langchain_\\data\\keyframes\".replace(\"\\\\\", \"/\")\n",
    "path = list(Path(p).rglob(\"*.jpg\"))\n",
    "shape = []\n",
    "for p in tqdm.tqdm(path):\n",
    "    img = cv2.imread(str(p), -1)\n",
    "    rz = cv2.resize(img, dsize=(320, 180), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(str(p), rz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i in range(5):\n",
    "    img = Image.open(data.keyframes[idx[i]]).convert(\"RGB\")\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f\"Sim: {sim[idx[i]]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33759177",
   "metadata": {},
   "source": [
    "# Extract clip embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip import clip\n",
    "model, preprocess = clip.load(\"RN50\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class KeyframeDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.list_kf = os.listdir(folder_path)\n",
    "        self.list_kf.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_kf)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.folder_path, self.list_kf[idx])\n",
    "        img = Image.open(img_path)\n",
    "        img = preprocess(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\ADMIN\\Downloads\\rag_langchain_\\data\\keyframes\".replace('\\\\', '/')\n",
    "len(os.listdir(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd95d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = r\"C:\\Users\\ADMIN\\Downloads\\rag_langchain_\\data\\clip_embs\".replace(\"\\\\\", \"/\")\n",
    "exist_name = os.listdir(out_dir)\n",
    "for idx, x in enumerate(exist_name):\n",
    "    exist_name[idx] = x.split(\".\")[0]\n",
    "\n",
    "for folder in os.listdir(folder_path):\n",
    "    if folder in exist_name:\n",
    "        print(f\"Skip folder: {folder}\")\n",
    "        continue\n",
    "    folder_path_full = os.path.join(folder_path, folder).replace(\"\\\\\", \"/\")\n",
    "    data = KeyframeDataset(folder_path_full)\n",
    "    dataloader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "    \n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader, desc=f\"Folder {folder}\"):\n",
    "            features = model.encode_image(batch)\n",
    "            features = features.cpu().numpy()\n",
    "            all_features.extend(features)\n",
    "    \n",
    "    all_features = np.array(all_features)\n",
    "    np.save(os.path.join(out_dir, folder + \".npy\"), all_features)\n",
    "\n",
    "print(\"-\"*10, \"DONE\", \"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_embeddings(embeddings):\n",
    "    if embeddings.ndim == 1:\n",
    "        norm = np.linalg.norm(embeddings)\n",
    "        return embeddings / norm\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    return embeddings / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441afda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a cat\"\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(clip.tokenize([text]))[0]\n",
    "text_features = norm(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be911f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = torch.nn.functional.softmax(embs @ text_features, dim=-1).cpu().numpy()\n",
    "sort_ids = np.argsort(-sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(imgs[sort_ids[i]].permute(1, 2, 0))\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"Top {i+1} - {sim[sort_ids[i]]:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c643c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
